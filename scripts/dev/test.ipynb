{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5574e419-3a52-4e87-9b98-db45920fbc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from vars import *\n",
    "from datetime import date\n",
    "from functions import flatten_json, loadConfigs\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.jars\", \"/jars/postgresql-42.2.5.jar\") \\\n",
    "    .getOrCreate()\n",
    "loadConfigs(spark.sparkContext)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a8b447-f860-4447-b17c-a7de1db0f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime('%Y%m%d')\n",
    "today = 20230325\n",
    "dateid = int(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2018490-75c6-4cdc-b585-cfe6fc0f775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .parquet(f\"s3a://{minio_bucket}/processed/popular_20230323.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac5b5598-2c6b-4034-8241-7062386edb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6aecbe34-f9cb-46f8-b972-4d35cd527fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = spark.read.option(\"header\", \"true\") \\\n",
    "    .parquet(f\"s3a://{minio_bucket}/raw/popular_{today}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec5898-076b-4e6f-a7c1-3296f233d8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2594c530-43d2-4bb2-b34d-a81a549139e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_name = \"staging.raw_data\"\n",
    "# mode = \"append\"\n",
    "# properties = {\"user\": postgres_user, \"password\": postgres_pass}\n",
    "# df.write.jdbc(url=jdbc_url, table=table_name, mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e8fa6c4-727b-43f0-97d7-7cd8d48abbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM staging.raw_data LIMIT 0\"\n",
    "\n",
    "df_target = spark.read.jdbc(url=postgres_url,\n",
    "                     table=\"( {} ) as mytable\".format(sql_query),\n",
    "                     properties=postgres_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af4ba537-8719-47f7-b45e-2239904adbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_schema = df_source.schema\n",
    "target_schema = df_target.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75197396-3992-4a38-afff-89b750d00fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0932622-5e09-4ce5-bbf1-d8e79fc8820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = []\n",
    "for field in source_schema.fields:\n",
    "    if field.name not in [f.name for f in target_schema.fields]:\n",
    "        col_name = field.name\n",
    "        col_name = col_name.replace('>','_')\n",
    "        missing_columns.append((col_name, field.dataType))\n",
    "        \n",
    "\n",
    "alter_table_command = \"ALTER TABLE staging.raw_data\\nADD COLUMN \"\n",
    "for col in missing_columns:\n",
    "    alter_table_command += \"{} {},\\n\".format(col[0], col[1])\n",
    "    \n",
    "alter_table_command = alter_table_command[:-2] + \";\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52d5cd3e-401e-4d3a-a98b-642ccebf45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alter_table_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c450e32-7be6-4333-94c3-37100b8b3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(alter_table_command).write.jdbc(table=\"staging.raw_data\", mode=\"append\", properties=postgres_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6187eab1-0e32-4299-9982-b886b8c13a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # execute the SQL command using JDBC\n",
    "# spark.read.jdbc(url=postgres_url,\n",
    "#                 table=\"( {} )\".format(alter_table_command),\n",
    "#                 properties=postgres_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6bec4-25e0-44e1-a068-6fe32471eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
